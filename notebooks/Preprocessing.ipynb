{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps\n",
    "\n",
    "## 0) Read in data\n",
    "## 1) Basic conversions and drops\n",
    "## 2) Joining search queries to make single-query interaction vectors, and user interaction vectors\n",
    "## 3) Create Context vector\n",
    "## 4) Finally, an example on how to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lenskit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Read in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/awd275/Search_and_Discovery/sad_final_project/data/raw/small_100_results'\n",
    "\n",
    "columns_to_read = ['search_result_id','search_request_id', 'hotel_id', 'user_id','label', 'check_in', 'check_out',\n",
    "       'reward_program_hash', 'advance_purchase_days',\n",
    "       'number_of_nights', 'number_of_rooms', 'number_of_adults',\n",
    "       'srq_latitude', 'srq_longitude', 'check_in_weekday',\n",
    "       'check_out_weekday', 'srq_weekhour', 'weekday_travel',\n",
    "       'weekend_travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_dir,columns=columns_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Basic conversions and drops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_conversions(df):\n",
    "    '''\n",
    "    IMPORTANT!!\n",
    "    1) Adds a hotel_index column, this is assigns each hotel_id a number from 0 to len(hotel_id)-1. This index\n",
    "    is used for our interaction vector, which is a len(hotel_id)-length vector with the interaction label\n",
    "    as the entries.\n",
    "    \n",
    "    2) Drops users with no user_id (aka, anonymous/first time users)\n",
    "    3) subtracts 1e^10 from user_id (ask eric why)\n",
    "    4) converts date time strings into pandas datetime objects\n",
    "    '''\n",
    "    hotel_id_to_hotel_index = dict((hotel_id, i) for (i, hotel_id) in enumerate(df['hotel_id'].unique()))\n",
    "    df['hotel_index']= df['hotel_id'].map(hotel_id_to_hotel_index)\n",
    "    df.drop(df.loc[df['user_id'].isna()].index, inplace=True)\n",
    "    df['user_id'] = df['user_id'] - 1e10\n",
    "    df['check_in'] = pd.to_datetime(df['check_in'],yearfirst=True)\n",
    "    df['check_out'] = pd.to_datetime(df['check_out'],yearfirst=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_conversions(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining search queries by search_result_id, and getting single/entire interaction_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_id_to_query_struct_dict(df):\n",
    "    '''\n",
    "    returns a dictionary of user_id -> \"query_struct.\"\n",
    "    check create_query_struct_for_user for what a \"query_struct\" is\n",
    "    '''\n",
    "    unique_user_ids = df['user_id'].unique()\n",
    "    user_id_to_query_struct_dict = {user_id : create_query_struct_for_user(df,user_id)\n",
    "                                    for user_id in unique_user_ids}\n",
    "    return user_id_to_query_struct_dict\n",
    "\n",
    "\n",
    "def create_query_struct_for_user(df,user_id):\n",
    "    '''\n",
    "    Returns a \"query struct\", which is a 2-tuple:\n",
    "    \n",
    "    (Assuming a given and fixed user_id):\n",
    "    \n",
    "    1st entry: dict of search_request_ids to a interaction_vec for that search request.\n",
    "        Note: The interaction_vec is a dict of hotel_index -> label for that hotel_index.\n",
    "              Importantly, this is a sparse vector format.\n",
    "              Thus, the 1st entry is a dict{search_request_id -> dict{hotel_idx->label}}\n",
    "              \n",
    "    2nd return: user_vector containing all of the label/interactions w/user_id = user_id\n",
    "    \n",
    "    '''\n",
    "    # Select only the entries for the user we care about\n",
    "    df_user_id = df[df['user_id']==user_id]\n",
    "    # get all of their searches (search_id)\n",
    "    unique_search_ids_per_user = df_user_id['search_request_id'].unique()\n",
    "    # Loop over each search, storing the interaction for each search query\n",
    "    interaction_vecs_per_query = []\n",
    "    for sr_id in unique_search_ids_per_user:\n",
    "        # Select only entries for each search request\n",
    "        df_sr_user_id = df_user_id[df_user_id['search_request_id']==sr_id] \n",
    "        # Create a dict of {hotel_index:label}\n",
    "        interaction_sparse_vec = pd.Series(df_sr_user_id['label'].values,index=df_sr_user_id['hotel_index']).to_dict()\n",
    "        # Add it to vector\n",
    "        interaction_vecs_per_query.append(interaction_sparse_vec)\n",
    "    \n",
    "    #make a dict of search_ids to interactions_vec\n",
    "    search_id_to_interaction_vec = dict(zip(unique_search_ids_per_user,interaction_vecs_per_query))\n",
    "    \n",
    "    # Merge all the interactions to get the user's entire interaction vec\n",
    "    user_interaction_vec = merge_dicts_with_max(interaction_vecs_per_query)\n",
    "    \n",
    "    return search_id_to_interaction_vec,user_interaction_vec\n",
    "\n",
    "def get_single_query_interaction_vec(user_id_to_query_struct_dict,user_id,sr_id):\n",
    "    return user_id_to_query_struct_dict[user_id][0][sr_id]\n",
    "def get_user_entire_interaction_vec(user_id_to_query_struct_dict,user_id):\n",
    "    return user_id_to_query_struct_dict[user_id][1]\n",
    "\n",
    "def merge_dicts_with_max(dict_list):\n",
    "    ''' \n",
    "    merge a list of dictionaries\n",
    "    if their keys overlap, return the max.\n",
    "    e.g. {a:1,b:1}\n",
    "         {b:2,c:2}\n",
    "         merged into {a:1,b:2,c:2}\n",
    "    \n",
    "    We need this in order to merge a single users interaction vectors. Consider if a user\n",
    "    does two queries, and ends up buying the same hotel twice. \n",
    "    '''\n",
    "    return_dict = {}\n",
    "    for dict_ in dict_list:\n",
    "        for key in dict_:\n",
    "            if key in return_dict:\n",
    "                return_dict[key] = max(return_dict[key],dict_[key])\n",
    "            else:\n",
    "                return_dict[key] = dict_[key]\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_query_struct_dict = create_user_id_to_query_struct_dict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Context Vector and encodes the categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_df_and_cat_encoder(df,cat_vars_to_use):\n",
    "    '''\n",
    "    Creates the context_dataframe and cat_encoder\n",
    "    \n",
    "    returns a 2-tuple,\n",
    "    1st: return context_dataframe, which is a dataframe with !search_request_id as the index!\n",
    "    2nd: returns a sklearn OneHotEncoder, which has been trained on context_df['cat_vars_to_use']\n",
    "    \n",
    "    '''\n",
    "    # Our df contains 100~ results for each search request id. Each of the 100 results have the same query info\n",
    "    # e.g, they all have the same values for reward_program_has, check_in_weekday,number_of_nights,etc\n",
    "    # We only need one row out of those 100 to properly get the context. \n",
    "    # Here, we grab the first row\n",
    "    sr_id_to_first_index_df = pd.DataFrame([[key,val.values[0]]\n",
    "                              for key,val in df.groupby('search_request_id').groups.items()], \n",
    "                              columns=['search_request_id','first_index'])\n",
    "    context_df = df.loc[sr_id_to_first_index_df['first_index'].values]\n",
    "    context_df.set_index('search_request_id',inplace=True)\n",
    "    #Encode the categorical variables\n",
    "    cat_onehot_enc = OneHotEncoder()\n",
    "    cat_onehot_enc.fit(context_df[cat_vars_to_use])    \n",
    "    \n",
    "    \n",
    "    return context_df,cat_onehot_enc\n",
    "\n",
    "def create_context_vec(context_df, cat_onehot_enc, cat_vars_to_use, quant_vars_to_use, sr_id):\n",
    "    '''\n",
    "    returns a np.vector which contains the context information.\n",
    "            The categorical features have already been encoded via cat_onehot_enc\n",
    "    \n",
    "    '''\n",
    "    #Get User id for this query\n",
    "    user_id = context_df.loc[sr_id]['user_id']\n",
    "    # Get and encode the categorical features for this query\n",
    "    context_cat_pre_enc = context_df.loc[sr_id][cat_vars_to_use]\n",
    "    #Reshape if we're only dealing with one row\n",
    "    if len(context_cat_pre_enc.shape) == 1:\n",
    "        context_cat_pre_enc = context_cat_pre_enc.values.reshape(1,-1)\n",
    "    context_cat_enc = cat_onehot_enc.transform(context_cat_pre_enc).todense()\n",
    "    \n",
    "    # Get the quantitative features for this query\n",
    "    context_quant = context_df.loc[sr_id][quant_vars_to_use].to_numpy()\n",
    "    if len(context_quant.shape) == 1:\n",
    "        context_quant = context_cat_pre_enc.reshape(1,-1)\n",
    "    #stack the encoded categorical features and quantitative features\n",
    "    context_vec = np.hstack((context_cat_enc,context_quant))\n",
    "    # return the context\n",
    "    return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example \n",
    "test_sr_id = 10064244538\n",
    "\n",
    "cat_vars_to_use = ['reward_program_hash',\n",
    "                    'check_in_weekday',\n",
    "                    'check_out_weekday',\n",
    "                    'weekday_travel',\n",
    "                    'weekend_travel']\n",
    "quant_vars_to_use = ['check_in',\n",
    "                     'check_out',\n",
    "                     'advance_purchase_days',\n",
    "                     'number_of_nights',\n",
    "                     'number_of_rooms',\n",
    "                     'number_of_adults',\n",
    "                     'srq_latitude',\n",
    "                     'srq_longitude',\n",
    "                    ]\n",
    "\n",
    "context_df, cat_onehot_enc = create_context_df_and_cat_encoder(df, cat_vars_to_use)\n",
    "context_vec = create_context_vec(context_df, cat_onehot_enc, cat_vars_to_use, quant_vars_to_use, test_sr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell here to stop jupyter notebook from running to the finish\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lenskit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_id_from_sr_id(context_df,sr_id):\n",
    "    '''\n",
    "    Make sure you use context df, as that is indexed by search_id (this will speed things up)\n",
    "    '''\n",
    "    return context_df.loc[sr_id]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 Read in Data\n",
    "data_dir = '/home/awd275/Search_and_Discovery/sad_final_project/data/raw/small_100_results'\n",
    "\n",
    "columns_to_read = ['search_result_id','search_request_id', 'hotel_id', 'user_id','label', 'check_in', 'check_out',\n",
    "       'reward_program_hash', 'advance_purchase_days',\n",
    "       'number_of_nights', 'number_of_rooms', 'number_of_adults',\n",
    "       'srq_latitude', 'srq_longitude', 'check_in_weekday',\n",
    "       'check_out_weekday', 'srq_weekhour', 'weekday_travel',\n",
    "       'weekend_travel']\n",
    "df = pd.read_parquet(data_dir,columns=columns_to_read)\n",
    "\n",
    "# Step 1, basic drops and conversions\n",
    "df = df_conversions(df)\n",
    "\n",
    "# Step 2, create dict of user_id -> query_struct\n",
    "user_id_to_query_struct_dict = create_user_id_to_query_struct_dict(df)\n",
    "\n",
    "\n",
    "# Step 3, Create context_df and encoder vector\n",
    "\n",
    "context_df, cat_onehot_enc = create_context_df_and_cat_encoder(df, cat_vars_to_use)\n",
    "context_vec = create_context_vec(context_df, cat_onehot_enc, cat_vars_to_use, quant_vars_to_use, test_sr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sr_id = 10064244538\n",
    "\n",
    "cat_vars_to_use = ['reward_program_hash',\n",
    "                    'check_in_weekday',\n",
    "                    'check_out_weekday',\n",
    "                    'weekday_travel',\n",
    "                    'weekend_travel']\n",
    "quant_vars_to_use = ['check_in',\n",
    "                     'check_out',\n",
    "                     'advance_purchase_days',\n",
    "                     'number_of_nights',\n",
    "                     'number_of_rooms',\n",
    "                     'number_of_adults',\n",
    "                     'srq_latitude',\n",
    "                     'srq_longitude',\n",
    "                    ]\n",
    "\n",
    "# Create context vector\n",
    "context_vec = create_context_vec(context_df, cat_onehot_enc, cat_vars_to_use, quant_vars_to_use, test_sr_id)\n",
    "user_id = get_user_id_from_sr_id(context_df,test_sr_id)\n",
    "# Get single_interaction_vec for this sr_id and user's entire interaction vec\n",
    "single_query_interaction_vec = get_single_query_interaction_vec(user_id_to_query_struct_dict, user_id, test_sr_id)\n",
    "user_entire_interaction_vec = get_user_entire_interaction_vec(user_id_to_query_struct_dict, user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "         1.0, 0.0, 0.0, 1.0, 3312343131, '6', '7', False, True]],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311836.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 4299: 0,\n",
       " 23350: 0,\n",
       " 23642: 0,\n",
       " 40000: 0,\n",
       " 24625: 0,\n",
       " 14149: 0,\n",
       " 34008: 0,\n",
       " 9693: 0,\n",
       " 4195: 0,\n",
       " 12087: 2,\n",
       " 30127: 0,\n",
       " 30020: 0,\n",
       " 9686: 0,\n",
       " 18782: 0,\n",
       " 23528: 0,\n",
       " 13564: 0,\n",
       " 24769: 0,\n",
       " 29160: 0,\n",
       " 4604: 0,\n",
       " 28934: 0,\n",
       " 298: 0,\n",
       " 43659: 0,\n",
       " 21410: 0,\n",
       " 27862: 0,\n",
       " 17332: 0,\n",
       " 36062: 0,\n",
       " 43872: 0,\n",
       " 51595: 0,\n",
       " 32243: 0,\n",
       " 58402: 0,\n",
       " 2413: 0,\n",
       " 33592: 0,\n",
       " 34747: 0,\n",
       " 37597: 0,\n",
       " 32990: 0,\n",
       " 20658: 0,\n",
       " 46501: 0,\n",
       " 19823: 0,\n",
       " 22933: 0,\n",
       " 41953: 0,\n",
       " 43156: 0,\n",
       " 40350: 0,\n",
       " 7951: 0,\n",
       " 13294: 0,\n",
       " 15456: 0,\n",
       " 22450: 0,\n",
       " 30126: 0,\n",
       " 44734: 0,\n",
       " 21409: 0,\n",
       " 48162: 0,\n",
       " 7828: 0,\n",
       " 14678: 0,\n",
       " 16991: 0,\n",
       " 52609: 0,\n",
       " 34022: 0,\n",
       " 12553: 0,\n",
       " 44131: 0,\n",
       " 38624: 0,\n",
       " 24173: 0,\n",
       " 31547: 0,\n",
       " 39047: 0,\n",
       " 31315: 0,\n",
       " 30968: 0,\n",
       " 8622: 0,\n",
       " 37898: 0,\n",
       " 10164: 0,\n",
       " 31243: 0,\n",
       " 30553: 0,\n",
       " 19313: 0,\n",
       " 95025: 0,\n",
       " 14528: 0,\n",
       " 41208: 0,\n",
       " 32067: 0,\n",
       " 22846: 0,\n",
       " 28462: 0,\n",
       " 20762: 0,\n",
       " 13851: 0,\n",
       " 19955: 0,\n",
       " 30034: 0,\n",
       " 24024: 0,\n",
       " 30373: 0,\n",
       " 24174: 0,\n",
       " 16449: 0,\n",
       " 29271: 0,\n",
       " 21168: 0,\n",
       " 16450: 0,\n",
       " 36007: 0,\n",
       " 37897: 0,\n",
       " 37582: 0,\n",
       " 52319: 0,\n",
       " 1199: 0,\n",
       " 8621: 0,\n",
       " 22427: 0,\n",
       " 21546: 0,\n",
       " 20751: 0,\n",
       " 10163: 0,\n",
       " 38357: 0,\n",
       " 25902: 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_query_interaction_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 4299: 0,\n",
       " 23350: 0,\n",
       " 23642: 0,\n",
       " 40000: 0,\n",
       " 24625: 0,\n",
       " 14149: 0,\n",
       " 34008: 0,\n",
       " 9693: 0,\n",
       " 4195: 0,\n",
       " 12087: 2,\n",
       " 30127: 0,\n",
       " 30020: 0,\n",
       " 9686: 0,\n",
       " 18782: 0,\n",
       " 23528: 0,\n",
       " 13564: 0,\n",
       " 24769: 0,\n",
       " 29160: 0,\n",
       " 4604: 0,\n",
       " 28934: 0,\n",
       " 298: 0,\n",
       " 43659: 0,\n",
       " 21410: 0,\n",
       " 27862: 0,\n",
       " 17332: 0,\n",
       " 36062: 0,\n",
       " 43872: 0,\n",
       " 51595: 0,\n",
       " 32243: 0,\n",
       " 58402: 0,\n",
       " 2413: 0,\n",
       " 33592: 0,\n",
       " 34747: 0,\n",
       " 37597: 0,\n",
       " 32990: 0,\n",
       " 20658: 0,\n",
       " 46501: 0,\n",
       " 19823: 0,\n",
       " 22933: 0,\n",
       " 41953: 0,\n",
       " 43156: 0,\n",
       " 40350: 0,\n",
       " 7951: 0,\n",
       " 13294: 0,\n",
       " 15456: 0,\n",
       " 22450: 0,\n",
       " 30126: 0,\n",
       " 44734: 0,\n",
       " 21409: 0,\n",
       " 48162: 0,\n",
       " 7828: 0,\n",
       " 14678: 0,\n",
       " 16991: 0,\n",
       " 52609: 0,\n",
       " 34022: 0,\n",
       " 12553: 0,\n",
       " 44131: 0,\n",
       " 38624: 0,\n",
       " 24173: 0,\n",
       " 31547: 0,\n",
       " 39047: 0,\n",
       " 31315: 0,\n",
       " 30968: 0,\n",
       " 8622: 0,\n",
       " 37898: 0,\n",
       " 10164: 0,\n",
       " 31243: 0,\n",
       " 30553: 0,\n",
       " 19313: 0,\n",
       " 95025: 0,\n",
       " 14528: 0,\n",
       " 41208: 0,\n",
       " 32067: 0,\n",
       " 22846: 0,\n",
       " 28462: 0,\n",
       " 20762: 0,\n",
       " 13851: 0,\n",
       " 19955: 0,\n",
       " 30034: 0,\n",
       " 24024: 0,\n",
       " 30373: 0,\n",
       " 24174: 0,\n",
       " 16449: 0,\n",
       " 29271: 0,\n",
       " 21168: 0,\n",
       " 16450: 0,\n",
       " 36007: 0,\n",
       " 37897: 0,\n",
       " 37582: 0,\n",
       " 52319: 0,\n",
       " 1199: 0,\n",
       " 8621: 0,\n",
       " 22427: 0,\n",
       " 21546: 0,\n",
       " 20751: 0,\n",
       " 10163: 0,\n",
       " 38357: 0,\n",
       " 25902: 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_entire_interaction_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes / BS below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables List\n",
    "\n",
    "'search_result_id', # don't need  \n",
    "'search_request_id', can use to join each search, doesnt go into model  \n",
    "'hotel_id',              categorical  \n",
    "'user_id',               categorical  \n",
    "'label',                 ordinal (0,1,2,3)  \n",
    "'check_in',              quantitative (after date time conversion)   \n",
    "'check_out',             quantitative (after date time conversion)  \n",
    "'reward_program_hash',  categorical  \n",
    "'advance_purchase_days', quantitative  \n",
    "'number_of_nights',      quantitative  \n",
    "'number_of_rooms',       quantitative  \n",
    "'number_of_adults',      quantitative  \n",
    "'srq_latitude',          quantitative  \n",
    "'srq_longitude',         quantitative  \n",
    "'check_in_weekday',      categorical  \n",
    "'check_out_weekday',     categorical  \n",
    "'srq_weekhour',          categorical (Probably don't need)  \n",
    "'weekday_travel',        categorical  \n",
    "'weekend_travel'         categorical  \n",
    "  \n",
    "  \n",
    "User_id    \n",
    "hotel_id    \n",
    "\n",
    "\n",
    "Categorical variables:  \n",
    "    reward_program_hash  \n",
    "    check_in_weekday  \n",
    "    check_out_weekday  \n",
    "    weekday_travel  \n",
    "    weekend_travel   \n",
    "    \n",
    "quantitative variables  \n",
    "advance_purchase_days  \n",
    "number_of_nights  \n",
    "number_of_adults  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch flow description:\n",
    "\n",
    "Three inputs (two of them get concatenated): Single interaction for specific user, query, and all interactions for specific user.\n",
    "\n",
    "Concatenate single interaction query for specific user and query, and send to one encoder.\n",
    "Send all interactions for a specific user to another encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data of shape (427504, 19) from /scratch/work/js11133/sad_data/raw/full/train/0012_part_00.parquet\n",
      "Reading in data of shape (427556, 19) from /scratch/work/js11133/sad_data/raw/full/train/0008_part_00.parquet\n",
      "Reading in data of shape (427460, 19) from /scratch/work/js11133/sad_data/raw/full/train/0049_part_00.parquet\n",
      "Reading in data of shape (427612, 19) from /scratch/work/js11133/sad_data/raw/full/train/0025_part_00.parquet\n",
      "Reading in data of shape (427459, 19) from /scratch/work/js11133/sad_data/raw/full/train/0061_part_00.parquet\n",
      "Reading in data of shape (427550, 19) from /scratch/work/js11133/sad_data/raw/full/train/0060_part_00.parquet\n",
      "Reading in data of shape (427521, 19) from /scratch/work/js11133/sad_data/raw/full/train/0004_part_00.parquet\n",
      "Reading in data of shape (427550, 19) from /scratch/work/js11133/sad_data/raw/full/train/0034_part_00.parquet\n",
      "Reading in data of shape (427560, 19) from /scratch/work/js11133/sad_data/raw/full/train/0081_part_00.parquet\n",
      "Reading in data of shape (427433, 19) from /scratch/work/js11133/sad_data/raw/full/train/0031_part_00.parquet\n",
      "Reading in data of shape (427545, 19) from /scratch/work/js11133/sad_data/raw/full/train/0083_part_00.parquet\n",
      "Reading in data of shape (427507, 19) from /scratch/work/js11133/sad_data/raw/full/train/0095_part_00.parquet\n",
      "Reading in data of shape (427445, 19) from /scratch/work/js11133/sad_data/raw/full/train/0039_part_00.parquet\n",
      "Reading in data of shape (427431, 19) from /scratch/work/js11133/sad_data/raw/full/train/0092_part_00.parquet\n",
      "Reading in data of shape (427547, 19) from /scratch/work/js11133/sad_data/raw/full/train/0009_part_00.parquet\n",
      "Reading in data of shape (427503, 19) from /scratch/work/js11133/sad_data/raw/full/train/0054_part_00.parquet\n",
      "Reading in data of shape (427321, 19) from /scratch/work/js11133/sad_data/raw/full/train/0003_part_00.parquet\n",
      "Reading in data of shape (427389, 19) from /scratch/work/js11133/sad_data/raw/full/train/0021_part_00.parquet\n",
      "Reading in data of shape (427514, 19) from /scratch/work/js11133/sad_data/raw/full/train/0048_part_00.parquet\n",
      "Reading in data of shape (427491, 19) from /scratch/work/js11133/sad_data/raw/full/train/0052_part_00.parquet\n",
      "Reading in data of shape (427568, 19) from /scratch/work/js11133/sad_data/raw/full/train/0073_part_00.parquet\n",
      "Reading in data of shape (427296, 19) from /scratch/work/js11133/sad_data/raw/full/train/0068_part_00.parquet\n",
      "Reading in data of shape (427778, 19) from /scratch/work/js11133/sad_data/raw/full/train/0046_part_00.parquet\n",
      "Reading in data of shape (427820, 19) from /scratch/work/js11133/sad_data/raw/full/train/0077_part_00.parquet\n",
      "Reading in data of shape (427713, 19) from /scratch/work/js11133/sad_data/raw/full/train/0014_part_00.parquet\n",
      "Reading in data of shape (427448, 19) from /scratch/work/js11133/sad_data/raw/full/train/0047_part_00.parquet\n",
      "Reading in data of shape (427411, 19) from /scratch/work/js11133/sad_data/raw/full/train/0053_part_00.parquet\n",
      "Reading in data of shape (427500, 19) from /scratch/work/js11133/sad_data/raw/full/train/0026_part_00.parquet\n",
      "Reading in data of shape (427534, 19) from /scratch/work/js11133/sad_data/raw/full/train/0056_part_00.parquet\n",
      "Reading in data of shape (427419, 19) from /scratch/work/js11133/sad_data/raw/full/train/0071_part_00.parquet\n",
      "Reading in data of shape (427392, 19) from /scratch/work/js11133/sad_data/raw/full/train/0005_part_00.parquet\n",
      "Reading in data of shape (427340, 19) from /scratch/work/js11133/sad_data/raw/full/train/0062_part_00.parquet\n",
      "Reading in data of shape (427595, 19) from /scratch/work/js11133/sad_data/raw/full/train/0017_part_00.parquet\n",
      "Reading in data of shape (427499, 19) from /scratch/work/js11133/sad_data/raw/full/train/0000_part_00.parquet\n",
      "Reading in data of shape (427431, 19) from /scratch/work/js11133/sad_data/raw/full/train/0059_part_00.parquet\n",
      "Reading in data of shape (427421, 19) from /scratch/work/js11133/sad_data/raw/full/train/0090_part_00.parquet\n",
      "Reading in data of shape (427462, 19) from /scratch/work/js11133/sad_data/raw/full/train/0023_part_00.parquet\n",
      "Reading in data of shape (427318, 19) from /scratch/work/js11133/sad_data/raw/full/train/0069_part_00.parquet\n",
      "Reading in data of shape (427866, 19) from /scratch/work/js11133/sad_data/raw/full/train/0082_part_00.parquet\n",
      "Reading in data of shape (427349, 19) from /scratch/work/js11133/sad_data/raw/full/train/0087_part_00.parquet\n",
      "Reading in data of shape (427591, 19) from /scratch/work/js11133/sad_data/raw/full/train/0022_part_00.parquet\n",
      "Reading in data of shape (427635, 19) from /scratch/work/js11133/sad_data/raw/full/train/0038_part_00.parquet\n",
      "Reading in data of shape (427432, 19) from /scratch/work/js11133/sad_data/raw/full/train/0088_part_00.parquet\n",
      "Reading in data of shape (427553, 19) from /scratch/work/js11133/sad_data/raw/full/train/0001_part_00.parquet\n",
      "Reading in data of shape (427438, 19) from /scratch/work/js11133/sad_data/raw/full/train/0043_part_00.parquet\n",
      "Reading in data of shape (427310, 19) from /scratch/work/js11133/sad_data/raw/full/train/0024_part_00.parquet\n",
      "Reading in data of shape (427282, 19) from /scratch/work/js11133/sad_data/raw/full/train/0091_part_00.parquet\n",
      "Reading in data of shape (427745, 19) from /scratch/work/js11133/sad_data/raw/full/train/0042_part_00.parquet\n",
      "Reading in data of shape (427520, 19) from /scratch/work/js11133/sad_data/raw/full/train/0084_part_00.parquet\n",
      "Reading in data of shape (427443, 19) from /scratch/work/js11133/sad_data/raw/full/train/0055_part_00.parquet\n",
      "Reading in data of shape (427512, 19) from /scratch/work/js11133/sad_data/raw/full/train/0072_part_00.parquet\n",
      "Reading in data of shape (427533, 19) from /scratch/work/js11133/sad_data/raw/full/train/0089_part_00.parquet\n",
      "Reading in data of shape (427152, 19) from /scratch/work/js11133/sad_data/raw/full/train/0063_part_00.parquet\n",
      "Reading in data of shape (427679, 19) from /scratch/work/js11133/sad_data/raw/full/train/0076_part_00.parquet\n",
      "Reading in data of shape (427625, 19) from /scratch/work/js11133/sad_data/raw/full/train/0070_part_00.parquet\n",
      "Reading in data of shape (427690, 19) from /scratch/work/js11133/sad_data/raw/full/train/0079_part_00.parquet\n",
      "Reading in data of shape (427590, 19) from /scratch/work/js11133/sad_data/raw/full/train/0045_part_00.parquet\n",
      "Reading in data of shape (427440, 19) from /scratch/work/js11133/sad_data/raw/full/train/0019_part_00.parquet\n",
      "Reading in data of shape (427375, 19) from /scratch/work/js11133/sad_data/raw/full/train/0066_part_00.parquet\n",
      "Reading in data of shape (427562, 19) from /scratch/work/js11133/sad_data/raw/full/train/0010_part_00.parquet\n",
      "Reading in data of shape (427702, 19) from /scratch/work/js11133/sad_data/raw/full/train/0080_part_00.parquet\n",
      "Reading in data of shape (427412, 19) from /scratch/work/js11133/sad_data/raw/full/train/0093_part_00.parquet\n",
      "Reading in data of shape (427588, 19) from /scratch/work/js11133/sad_data/raw/full/train/0002_part_00.parquet\n",
      "Reading in data of shape (427447, 19) from /scratch/work/js11133/sad_data/raw/full/train/0035_part_00.parquet\n",
      "Reading in data of shape (427691, 19) from /scratch/work/js11133/sad_data/raw/full/train/0058_part_00.parquet\n",
      "Reading in data of shape (427411, 19) from /scratch/work/js11133/sad_data/raw/full/train/0064_part_00.parquet\n",
      "Reading in data of shape (427460, 19) from /scratch/work/js11133/sad_data/raw/full/train/0027_part_00.parquet\n",
      "Reading in data of shape (427273, 19) from /scratch/work/js11133/sad_data/raw/full/train/0067_part_00.parquet\n",
      "Reading in data of shape (427621, 19) from /scratch/work/js11133/sad_data/raw/full/train/0006_part_00.parquet\n",
      "Reading in data of shape (427650, 19) from /scratch/work/js11133/sad_data/raw/full/train/0028_part_00.parquet\n",
      "Reading in data of shape (427476, 19) from /scratch/work/js11133/sad_data/raw/full/train/0018_part_00.parquet\n",
      "Reading in data of shape (427532, 19) from /scratch/work/js11133/sad_data/raw/full/train/0032_part_00.parquet\n",
      "Reading in data of shape (427465, 19) from /scratch/work/js11133/sad_data/raw/full/train/0044_part_00.parquet\n",
      "Reading in data of shape (427603, 19) from /scratch/work/js11133/sad_data/raw/full/train/0094_part_00.parquet\n",
      "Reading in data of shape (427384, 19) from /scratch/work/js11133/sad_data/raw/full/train/0007_part_00.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data of shape (427476, 19) from /scratch/work/js11133/sad_data/raw/full/train/0016_part_00.parquet\n",
      "Reading in data of shape (427581, 19) from /scratch/work/js11133/sad_data/raw/full/train/0036_part_00.parquet\n",
      "Reading in data of shape (427248, 19) from /scratch/work/js11133/sad_data/raw/full/train/0065_part_00.parquet\n",
      "Reading in data of shape (427603, 19) from /scratch/work/js11133/sad_data/raw/full/train/0013_part_00.parquet\n",
      "Reading in data of shape (427311, 19) from /scratch/work/js11133/sad_data/raw/full/train/0020_part_00.parquet\n",
      "Reading in data of shape (427681, 19) from /scratch/work/js11133/sad_data/raw/full/train/0029_part_00.parquet\n",
      "Reading in data of shape (427548, 19) from /scratch/work/js11133/sad_data/raw/full/train/0011_part_00.parquet\n",
      "Reading in data of shape (427430, 19) from /scratch/work/js11133/sad_data/raw/full/train/0057_part_00.parquet\n",
      "Reading in data of shape (427178, 19) from /scratch/work/js11133/sad_data/raw/full/train/0051_part_00.parquet\n",
      "Reading in data of shape (427681, 19) from /scratch/work/js11133/sad_data/raw/full/train/0078_part_00.parquet\n",
      "Reading in data of shape (427703, 19) from /scratch/work/js11133/sad_data/raw/full/train/0040_part_00.parquet\n",
      "Reading in data of shape (427446, 19) from /scratch/work/js11133/sad_data/raw/full/train/0085_part_00.parquet\n",
      "Reading in data of shape (427475, 19) from /scratch/work/js11133/sad_data/raw/full/train/0033_part_00.parquet\n",
      "Reading in data of shape (427326, 19) from /scratch/work/js11133/sad_data/raw/full/train/0015_part_00.parquet\n",
      "Reading in data of shape (427514, 19) from /scratch/work/js11133/sad_data/raw/full/train/0037_part_00.parquet\n",
      "Reading in data of shape (427596, 19) from /scratch/work/js11133/sad_data/raw/full/train/0075_part_00.parquet\n",
      "Reading in data of shape (427595, 19) from /scratch/work/js11133/sad_data/raw/full/train/0074_part_00.parquet\n",
      "Reading in data of shape (427373, 19) from /scratch/work/js11133/sad_data/raw/full/train/0030_part_00.parquet\n",
      "Reading in data of shape (427640, 19) from /scratch/work/js11133/sad_data/raw/full/train/0086_part_00.parquet\n",
      "Reading in data of shape (427692, 19) from /scratch/work/js11133/sad_data/raw/full/train/0041_part_00.parquet\n",
      "Reading in data of shape (427572, 19) from /scratch/work/js11133/sad_data/raw/full/train/0050_part_00.parquet\n",
      "Total dataframe of shape (41040549, 19)\n",
      "Starting Step 1\n",
      "Starting Step 2\n",
      "Starting Step 3\n"
     ]
    }
   ],
   "source": [
    "!/home/awd275/miniconda3/envs/dsga3001/bin/python3  /home/awd275/Search_and_Discovery/sad_final_project/src/data/data_preprocessing_multvae.py /scratch/work/js11133/sad_data/raw/full/train /scratch/work/js11133/sad_data/processed/full/train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
