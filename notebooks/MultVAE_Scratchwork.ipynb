{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import pickle\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/raw/small_100'\n",
    "feature_path = 'src/data/schemas/output_data_schemas.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(data_path, num_partitions: None, randomize = True, verbose = True, columns = ['hotel_id', 'user_id','label']):\n",
    "    files = os.listdir(data_path)\n",
    "    if randomize:\n",
    "        random.shuffle(files)\n",
    "    \n",
    "    if num_partitions is None:\n",
    "        num_partitions = len(files)\n",
    "    \n",
    "    data = []\n",
    "    num_reads = 0\n",
    "    for file_path in files:\n",
    "        if num_reads >= num_partitions:\n",
    "            if verbose:\n",
    "                print('Finished reading {} .parquet Files'.format(num_partitions))\n",
    "            break\n",
    "        \n",
    "        _ , ext = os.path.splitext(file_path)\n",
    "        \n",
    "        if ext == '.parquet':\n",
    "            fp = os.path.join(data_path, file_path)\n",
    "            data.append(pd.read_parquet(os.path.join(data_path, file_path), columns = columns))\n",
    "            \n",
    "            if verbose:\n",
    "                print('Reading in data from {}'.format(fp))\n",
    "                print('Data of shape {}'.format(data[-1].shape))\n",
    "            \n",
    "            num_reads += 1\n",
    "        else: \n",
    "            continue\n",
    "    data = pd.concat(data, axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Total dataframe of shape {}'.format(data.shape))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from ../data/raw/small_100/0017_part_00.parquet\n",
      "Data of shape (49177, 3)\n",
      "Reading in data from ../data/raw/small_100/0050_part_00.parquet\n",
      "Data of shape (49072, 3)\n",
      "Reading in data from ../data/raw/small_100/0074_part_00.parquet\n",
      "Data of shape (49273, 3)\n",
      "Reading in data from ../data/raw/small_100/0049_part_00.parquet\n",
      "Data of shape (49153, 3)\n",
      "Reading in data from ../data/raw/small_100/0033_part_00.parquet\n",
      "Data of shape (49306, 3)\n",
      "Reading in data from ../data/raw/small_100/0095_part_00.parquet\n",
      "Data of shape (49172, 3)\n",
      "Reading in data from ../data/raw/small_100/0046_part_00.parquet\n",
      "Data of shape (49345, 3)\n",
      "Reading in data from ../data/raw/small_100/0001_part_00.parquet\n",
      "Data of shape (48765, 3)\n",
      "Reading in data from ../data/raw/small_100/0018_part_00.parquet\n",
      "Data of shape (49091, 3)\n",
      "Reading in data from ../data/raw/small_100/0083_part_00.parquet\n",
      "Data of shape (49067, 3)\n",
      "Reading in data from ../data/raw/small_100/0025_part_00.parquet\n",
      "Data of shape (49103, 3)\n",
      "Reading in data from ../data/raw/small_100/0062_part_00.parquet\n",
      "Data of shape (49285, 3)\n",
      "Reading in data from ../data/raw/small_100/0065_part_00.parquet\n",
      "Data of shape (49223, 3)\n",
      "Reading in data from ../data/raw/small_100/0058_part_00.parquet\n",
      "Data of shape (49018, 3)\n",
      "Reading in data from ../data/raw/small_100/0022_part_00.parquet\n",
      "Data of shape (49085, 3)\n",
      "Reading in data from ../data/raw/small_100/0084_part_00.parquet\n",
      "Data of shape (49114, 3)\n",
      "Reading in data from ../data/raw/small_100/0006_part_00.parquet\n",
      "Data of shape (49188, 3)\n",
      "Reading in data from ../data/raw/small_100/0041_part_00.parquet\n",
      "Data of shape (49257, 3)\n",
      "Reading in data from ../data/raw/small_100/0092_part_00.parquet\n",
      "Data of shape (48728, 3)\n",
      "Reading in data from ../data/raw/small_100/0009_part_00.parquet\n",
      "Data of shape (49477, 3)\n",
      "Reading in data from ../data/raw/small_100/0034_part_00.parquet\n",
      "Data of shape (49188, 3)\n",
      "Reading in data from ../data/raw/small_100/0073_part_00.parquet\n",
      "Data of shape (49204, 3)\n",
      "Reading in data from ../data/raw/small_100/0057_part_00.parquet\n",
      "Data of shape (49598, 3)\n",
      "Reading in data from ../data/raw/small_100/0010_part_00.parquet\n",
      "Data of shape (49184, 3)\n",
      "Reading in data from ../data/raw/small_100/0023_part_00.parquet\n",
      "Data of shape (49315, 3)\n",
      "Reading in data from ../data/raw/small_100/0085_part_00.parquet\n",
      "Data of shape (49291, 3)\n",
      "Reading in data from ../data/raw/small_100/0064_part_00.parquet\n",
      "Data of shape (49295, 3)\n",
      "Reading in data from ../data/raw/small_100/0059_part_00.parquet\n",
      "Data of shape (49445, 3)\n",
      "Reading in data from ../data/raw/small_100/0040_part_00.parquet\n",
      "Data of shape (49055, 3)\n",
      "Reading in data from ../data/raw/small_100/0007_part_00.parquet\n",
      "Data of shape (49103, 3)\n",
      "Reading in data from ../data/raw/small_100/0072_part_00.parquet\n",
      "Data of shape (49059, 3)\n",
      "Reading in data from ../data/raw/small_100/0093_part_00.parquet\n",
      "Data of shape (49263, 3)\n",
      "Reading in data from ../data/raw/small_100/0008_part_00.parquet\n",
      "Data of shape (49065, 3)\n",
      "Reading in data from ../data/raw/small_100/0035_part_00.parquet\n",
      "Data of shape (49158, 3)\n",
      "Reading in data from ../data/raw/small_100/0011_part_00.parquet\n",
      "Data of shape (48917, 3)\n",
      "Reading in data from ../data/raw/small_100/0056_part_00.parquet\n",
      "Data of shape (49264, 3)\n",
      "Reading in data from ../data/raw/small_100/0051_part_00.parquet\n",
      "Data of shape (49561, 3)\n",
      "Reading in data from ../data/raw/small_100/0016_part_00.parquet\n",
      "Data of shape (49062, 3)\n",
      "Reading in data from ../data/raw/small_100/0032_part_00.parquet\n",
      "Data of shape (49161, 3)\n",
      "Reading in data from ../data/raw/small_100/0094_part_00.parquet\n",
      "Data of shape (49030, 3)\n",
      "Reading in data from ../data/raw/small_100/0075_part_00.parquet\n",
      "Data of shape (48904, 3)\n",
      "Reading in data from ../data/raw/small_100/0048_part_00.parquet\n",
      "Data of shape (49492, 3)\n",
      "Reading in data from ../data/raw/small_100/0000_part_00.parquet\n",
      "Data of shape (49060, 3)\n",
      "Reading in data from ../data/raw/small_100/0047_part_00.parquet\n",
      "Data of shape (49400, 3)\n",
      "Reading in data from ../data/raw/small_100/0063_part_00.parquet\n",
      "Data of shape (49308, 3)\n",
      "Reading in data from ../data/raw/small_100/0019_part_00.parquet\n",
      "Data of shape (49478, 3)\n",
      "Reading in data from ../data/raw/small_100/0082_part_00.parquet\n",
      "Data of shape (49187, 3)\n",
      "Reading in data from ../data/raw/small_100/0024_part_00.parquet\n",
      "Data of shape (49143, 3)\n",
      "Reading in data from ../data/raw/small_100/0042_part_00.parquet\n",
      "Data of shape (49320, 3)\n",
      "Reading in data from ../data/raw/small_100/0005_part_00.parquet\n",
      "Data of shape (49135, 3)\n",
      "Reading in data from ../data/raw/small_100/0038_part_00.parquet\n",
      "Data of shape (49424, 3)\n",
      "Reading in data from ../data/raw/small_100/0087_part_00.parquet\n",
      "Data of shape (48970, 3)\n",
      "Reading in data from ../data/raw/small_100/0021_part_00.parquet\n",
      "Data of shape (49558, 3)\n",
      "Reading in data from ../data/raw/small_100/0066_part_00.parquet\n",
      "Data of shape (49169, 3)\n",
      "Reading in data from ../data/raw/small_100/0013_part_00.parquet\n",
      "Data of shape (49328, 3)\n",
      "Reading in data from ../data/raw/small_100/0088_part_00.parquet\n",
      "Data of shape (49206, 3)\n",
      "Reading in data from ../data/raw/small_100/0069_part_00.parquet\n",
      "Data of shape (49135, 3)\n",
      "Reading in data from ../data/raw/small_100/0054_part_00.parquet\n",
      "Data of shape (49025, 3)\n",
      "Reading in data from ../data/raw/small_100/0070_part_00.parquet\n",
      "Data of shape (49166, 3)\n",
      "Reading in data from ../data/raw/small_100/0037_part_00.parquet\n",
      "Data of shape (49239, 3)\n",
      "Reading in data from ../data/raw/small_100/0091_part_00.parquet\n",
      "Data of shape (48983, 3)\n",
      "Reading in data from ../data/raw/small_100/0030_part_00.parquet\n",
      "Data of shape (49206, 3)\n",
      "Reading in data from ../data/raw/small_100/0077_part_00.parquet\n",
      "Data of shape (49063, 3)\n",
      "Reading in data from ../data/raw/small_100/0053_part_00.parquet\n",
      "Data of shape (49217, 3)\n",
      "Reading in data from ../data/raw/small_100/0014_part_00.parquet\n",
      "Data of shape (49132, 3)\n",
      "Reading in data from ../data/raw/small_100/0029_part_00.parquet\n",
      "Data of shape (49456, 3)\n",
      "Reading in data from ../data/raw/small_100/0061_part_00.parquet\n",
      "Data of shape (49097, 3)\n",
      "Reading in data from ../data/raw/small_100/0026_part_00.parquet\n",
      "Data of shape (49192, 3)\n",
      "Reading in data from ../data/raw/small_100/0080_part_00.parquet\n",
      "Data of shape (49280, 3)\n",
      "Reading in data from ../data/raw/small_100/0002_part_00.parquet\n",
      "Data of shape (49193, 3)\n",
      "Reading in data from ../data/raw/small_100/0078_part_00.parquet\n",
      "Data of shape (49169, 3)\n",
      "Reading in data from ../data/raw/small_100/0045_part_00.parquet\n",
      "Data of shape (49100, 3)\n",
      "Reading in data from ../data/raw/small_100/0076_part_00.parquet\n",
      "Data of shape (49307, 3)\n",
      "Reading in data from ../data/raw/small_100/0031_part_00.parquet\n",
      "Data of shape (49276, 3)\n",
      "Reading in data from ../data/raw/small_100/0015_part_00.parquet\n",
      "Data of shape (48992, 3)\n",
      "Reading in data from ../data/raw/small_100/0028_part_00.parquet\n",
      "Data of shape (49340, 3)\n",
      "Reading in data from ../data/raw/small_100/0052_part_00.parquet\n",
      "Data of shape (49389, 3)\n",
      "Reading in data from ../data/raw/small_100/0027_part_00.parquet\n",
      "Data of shape (49235, 3)\n",
      "Reading in data from ../data/raw/small_100/0081_part_00.parquet\n",
      "Data of shape (49152, 3)\n",
      "Reading in data from ../data/raw/small_100/0060_part_00.parquet\n",
      "Data of shape (49068, 3)\n",
      "Reading in data from ../data/raw/small_100/0079_part_00.parquet\n",
      "Data of shape (49033, 3)\n",
      "Reading in data from ../data/raw/small_100/0044_part_00.parquet\n",
      "Data of shape (49480, 3)\n",
      "Reading in data from ../data/raw/small_100/0003_part_00.parquet\n",
      "Data of shape (49048, 3)\n",
      "Reading in data from ../data/raw/small_100/0004_part_00.parquet\n",
      "Data of shape (49223, 3)\n",
      "Reading in data from ../data/raw/small_100/0039_part_00.parquet\n",
      "Data of shape (49417, 3)\n",
      "Reading in data from ../data/raw/small_100/0043_part_00.parquet\n",
      "Data of shape (49045, 3)\n",
      "Reading in data from ../data/raw/small_100/0067_part_00.parquet\n",
      "Data of shape (49184, 3)\n",
      "Reading in data from ../data/raw/small_100/0086_part_00.parquet\n",
      "Data of shape (49041, 3)\n",
      "Reading in data from ../data/raw/small_100/0020_part_00.parquet\n",
      "Data of shape (49136, 3)\n",
      "Reading in data from ../data/raw/small_100/0068_part_00.parquet\n",
      "Data of shape (49207, 3)\n",
      "Reading in data from ../data/raw/small_100/0055_part_00.parquet\n",
      "Data of shape (49062, 3)\n",
      "Reading in data from ../data/raw/small_100/0012_part_00.parquet\n",
      "Data of shape (49141, 3)\n",
      "Reading in data from ../data/raw/small_100/0089_part_00.parquet\n",
      "Data of shape (49272, 3)\n",
      "Reading in data from ../data/raw/small_100/0036_part_00.parquet\n",
      "Data of shape (48967, 3)\n",
      "Reading in data from ../data/raw/small_100/0090_part_00.parquet\n",
      "Data of shape (49160, 3)\n",
      "Reading in data from ../data/raw/small_100/0071_part_00.parquet\n",
      "Data of shape (49121, 3)\n",
      "Total dataframe of shape (4722148, 3)\n"
     ]
    }
   ],
   "source": [
    "df = read_parquet(data_path, randomize = False, num_partitions = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/interim/final_reindex_train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('../data/interim/final_reindex_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_data = sparse.csr_matrix((new_data.label, (new_data.user_id, new_data.hotel_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_data.loc[new_data.user_id ==2].hotel_id == 10579).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = sparse_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    2,     4,     4, ..., 16311, 16312, 16313]),\n",
       " array([ 2760,  2519,  3594, ..., 56888, 64275, 96557]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dense == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( '../data/processed/user_to_queries.pkl','rb') as fp:\n",
    "    a = pickle.load(fp)\n",
    "    \n",
    "with open(os.path.join('../data/processed/hotel_hash.json'), 'r') as fp:\n",
    "    hotel_ids = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interactions = {key:value[1] for (key, value) in a.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6b8344068c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_interactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: (0, 1, 2)"
     ]
    }
   ],
   "source": [
    "user_interactions[0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotel_ids.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparse.dok_matrix((len(b.keys()),len(hotel_ids.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in user_interactions.keys():\n",
    "    for j in user_interactions[i].keys():\n",
    "        data[i,j] = user_interactions[i][j]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BasicHotelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path = None, dict_path = None):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            data_path (string): Path to the csv file\n",
    "        \"\"\"\n",
    "        if data_path is None:\n",
    "            raise ValueError('Please specify data_path')\n",
    "        if dict_path is None:\n",
    "            raise ValueError('Need path of hashes')\n",
    "        \n",
    "        _ , ext = os.path.splitext(data_path)\n",
    "        if ext != 'csv':\n",
    "            raise ValueError('Incorrect File to upload')\n",
    "        \n",
    "        _, ext2 = os.path.splitext(dict_path)\n",
    "        if ext2 != 'pkl':\n",
    "            raise ValueError('Incorrect File to use as indicies')\n",
    "        \n",
    "        with open(data_path,'rb') as fp:\n",
    "            self.data = pickle.load(fp)\n",
    "        \n",
    "        self.data = {key: value[1] for (key, value) in self.data.items()}\n",
    "\n",
    "        with open(os.path.join(dict_path, 'hotel_hash.json'), 'r') as fp:\n",
    "            self.hotel_length = len(json.load(fp))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data.keys())\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            if torch.is_tensor(idx):\n",
    "                idx = idx.tolist\n",
    "\n",
    "            user_interactions = [self.data[k] for k in idx] #list of dicts\n",
    "            sparse_dok = sparse.dok_matrix((len(idx),self.hotel_length))\n",
    "            for i in range(len(user_interactions)):\n",
    "                for j in user_interactions[i].keys():\n",
    "                    sparse_dok[i,j] = user_interactions[i][j]\n",
    "           \n",
    "            return torch.tensor(sparse_dok.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
